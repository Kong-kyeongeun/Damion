{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "data_path = Path('D:\\\\Data\\\\SMILE\\\\chest_xray')\n",
    "test = data_path / 'test'\n",
    "train = data_path / 'train'\n",
    "val = data_path / 'val'\n",
    "\n",
    "test_normal = test/ 'NORMAL'\n",
    "test_pneumonia = test/ 'PNEUMONIA'\n",
    "\n",
    "train_normal = train/ 'NORMAL'\n",
    "train_pneumonia = train/ 'PNEUMONIA'\n",
    "\n",
    "val_normal = val/ 'NORMAL'\n",
    "val_pneumonia = val/ 'PNEUMONIA'\n",
    "\n",
    "\n",
    "\n",
    "ex_img = train_normal/'IM-0115-0001.jpeg'\n",
    "Leena = data_path/'Lenna.png'\n",
    "\n",
    "\n",
    "def distinction1(img): #clahe girdsize가 크면 클수록 대비가 좋아지긴하나 부자연스러움\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize = (8,8)) \n",
    "    return clahe.apply(img)\n",
    "\n",
    "def distinction2(img): # 히스토그램 평활화\n",
    "    return cv2.equalizeHist(img)\n",
    "\n",
    "def distinction3(img): # 고주파 영역 clahe 영향 키우고 저주파영역 he영향 키움 clahe 자연스럽게 만든거라 생각 하면됨\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize = (8,8)) \n",
    "    clahe_img = clahe.apply(img)\n",
    "    he_img = cv2.equalizeHist(img)\n",
    "    std = img.std()\n",
    "    for dh in range(0,img.shape[0]-7,8):\n",
    "        for dw in range(0,img.shape[1]-7,8):\n",
    "            crop = img[dh:dh+8,dw:dw+8]\n",
    "            if std >= crop.std(): #상대적으로 저주파 지역\n",
    "                img[dh:dh+8,dw:dw+8] = clahe_img[dh:dh+8,dw:dw+8]\n",
    "            else:\n",
    "                img[dh:dh+8,dw:dw+8] = he_img[dh:dh+8,dw:dw+8]\n",
    "    return img\n",
    "        \n",
    "\n",
    "img = cv2.imread(str(ex_img), cv2.IMREAD_UNCHANGED)  ## 우선은 기존 사진을 불러오는게 맞을듯\n",
    "f_img = img.copy()\n",
    "f_img = cv2.resize(f_img ,dsize=(0,0),fx=0.6,fy=0.6, interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('img', f_img)\n",
    "\n",
    "height ,width = f_img.shape\n",
    "crow , ccol = int(height/2), int(width/2)\n",
    "dh, dw = int(height/20), int(width/20)\n",
    "\n",
    "img_zip = []\n",
    "for i in range(1,11):\n",
    "        \n",
    "    background = np.zeros((height, width),dtype= int)\n",
    "    f = np.fft.fft2(f_img)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    fshift2 = fshift.copy()\n",
    "    if i == 1:\n",
    "        fshift[crow-(dh*i):crow+(dh*i),ccol-(dw*i):ccol+(dw*i)] = 0\n",
    "        fshift2 = fshift2 - fshift\n",
    "    elif i ==10:\n",
    "        fshift[crow-(dh*(i-1)):crow+(dh*(i-1)),ccol-(dh*(i-1)):ccol+(dh*(i-1))] = 0\n",
    "        fshift2 = fshift2 - fshift\n",
    "    else: \n",
    "        fshift[crow-dh*(i-1):crow+dh*(i-1),ccol-dw*(i-1):ccol+dw*(i-1)] = 0\n",
    "        fshift2[crow-(dh*i):crow+(dh*i),ccol-(dw*i):ccol+(dw*i)] = 0\n",
    "        fshift2 = fshift -  fshift2\n",
    "    f_ishift = np.fft.ifftshift(fshift2)\n",
    "    img_back = np.fft.ifft2(f_ishift)\n",
    "    img_back = np.abs(img_back)\n",
    "    img_zip.append(img_back)\n",
    "    \n",
    "weight_img = np.zeros(f_img.shape, np.float32 )\n",
    "print(weight_img.shape)\n",
    "for i, _img in enumerate(img_zip):\n",
    "    if i <3 :\n",
    "        weight_img = weight_img + 1.2*_img\n",
    "    elif (i>=3)and(i<7):\n",
    "        weight_img = weight_img + 1.8*_img\n",
    "    else:\n",
    "        weight_img = weight_img + 0.6*_img\n",
    "        \n",
    "weight_img = weight_img.astype('uint8')\n",
    "cv2.imshow('weight_img', weight_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "def img_resize1(img,w,h):  # padding을 통해 size 맞춤\n",
    "    if((w/img.shape[1]) < h/img.shape[0]):\n",
    "        percent = w/img.shape[1]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_LINEAR)\n",
    "        dh = (h-img.shape[0])/2\n",
    "        M = np.array([[1,0,0],[0,1,dh]],dtype=np.float64)  \n",
    "        img = cv2.warpAffine(img, M, (w, h))\n",
    "    else:\n",
    "        percent = h/img.shape[0]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_LINEAR)\n",
    "        dw = (w-img.shape[1])/2\n",
    "        M = np.array([[1,0,dw],[0,1,0]],dtype=np.float64)  \n",
    "        img = cv2.warpAffine(img, M, (w, h))\n",
    "    return img\n",
    "        \n",
    "def img_resize2(img,w,h): #crop을 통해 size 맞춤\n",
    "    if((w/img.shape[1]) > h/img.shape[0]):\n",
    "        percent = w/img.shape[1]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_LINEAR)\n",
    "        print(\"1\",img.shape[0])\n",
    "        dh = (img.shape[0]-h)//2\n",
    "        img = img[dh:dh+h,:].copy()\n",
    "    else:\n",
    "        percent = h/img.shape[0]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_LINEAR)\n",
    "        print(\"2\",img.shape[1])\n",
    "        dw = (img.shape[1]-w)//2\n",
    "        img = img[:,dw:dw+w].copy()\n",
    "    return img\n",
    "    \n",
    "def img_resize3(img,w,h):  # resize1과 동일 보간법 차이\n",
    "    if((w/img.shape[1]) < h/img.shape[0]):\n",
    "        percent = w/img.shape[1]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_AREA)\n",
    "        dh = (h-img.shape[0])/2\n",
    "        M = np.array([[1,0,0],[0,1,dh]],dtype=np.float64)  \n",
    "        img = cv2.warpAffine(img, M, (w, h))\n",
    "    else:\n",
    "        percent = h/img.shape[0]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_AREA)\n",
    "        dw = (w-img.shape[1])/2\n",
    "        M = np.array([[1,0,dw],[0,1,0]],dtype=np.float64)  \n",
    "        img = cv2.warpAffine(img, M, (w, h))\n",
    "    return img\n",
    "        \n",
    "def img_resize4(img,w,h): #resize2과 동일 보간법 차이\n",
    "    if((w/img.shape[1]) > h/img.shape[0]):\n",
    "        percent = w/img.shape[1]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_AREA)\n",
    "        print(\"1\",img.shape[0])\n",
    "        dh = (img.shape[0]-h)//2\n",
    "        img = img[dh:dh+h,:].copy()\n",
    "    else:\n",
    "        percent = h/img.shape[0]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_AREA)\n",
    "        print(\"2\",img.shape[1])\n",
    "        dw = (img.shape[1]-w)//2\n",
    "        img = img[:,dw:dw+w].copy()\n",
    "    return img\n",
    "\n",
    "# test\n",
    "f_img = img.copy()\n",
    "cv2.imshow('before', f_img)\n",
    "f_img1 = img_resize1(f_img,600,500)\n",
    "f_img2 = img_resize3(f_img,600,500)\n",
    "print(f_img2.shape)\n",
    "cv2.imshow('after1', f_img1)\n",
    "cv2.imshow('after2', f_img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "f_img = img.copy()\n",
    "f_img2 = img_resize2(f_img,600,500)\n",
    "cv2.imshow('img', f_img2)\n",
    "cv2.imshow('img1', distinction1(f_img2))\n",
    "cv2.imshow('img2', distinction2(f_img2))\n",
    "cv2.imshow('img3', distinction3(f_img2))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "def norm1(img):\n",
    "    img = (img-img.min())/(img.max()-img.min())\n",
    "    return img\n",
    "\n",
    "def norm2(img):\n",
    "    img = (img - img.mean())/(img.std())\n",
    "    return img\n",
    "\n",
    "norm_cases = train_normal.glob('*.jpeg')\n",
    "pneumonia_cases = train_pneumonia.glob('*.jpeg')\n",
    "\n",
    "train_data = []\n",
    "for img in norm_cases:\n",
    "    train_data.append((img, 0))\n",
    "    \n",
    "for img in pneumonia_cases:\n",
    "    train_data.append((img, 1))\n",
    "\n",
    "train_data = pd.DataFrame(train_data, columns=['image', 'label'], index = None)\n",
    "train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "sns.countplot(x='label', data=train_data)\n",
    "\n",
    "# 배운점 \n",
    "    #os.listdir = 해당 디렉토리 파일명만 가져옴\n",
    "    #glob = 해당 디렉토리의 경로명까지 가져옴 ->내생각엔 사진을 불러오는 느낌이라기 보단 경로를 불러오는 느낌\n",
    "    #glob 은 generator를 반환함 \n",
    "    #dstack, stack, concatenate 차이 \n",
    "\n",
    "normal_cases = val_normal.glob('*.jpeg')\n",
    "pneumonia_cases = val_pneumonia.glob('*.jpeg')\n",
    "\n",
    "valid_data = []\n",
    "valid_labels = []\n",
    "\n",
    "for img in normal_cases:\n",
    "    img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)\n",
    "    img = distinction3(img) ## 선명도 높이기\n",
    "    img = img_resize3(img,224,224) ## img resize\n",
    "    img = norm1(img) ## 정규화 \n",
    "    img = np.dstack([img])\n",
    "    label = to_categorical(0, num_classes=2)\n",
    "    valid_data.append(img)\n",
    "    valid_labels.append(label)\n",
    "\n",
    "for img in pneumonia_cases:\n",
    "    img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)\n",
    "    img = distinction3(img) ## 선명도 높이기\n",
    "    img = img_resize3(img,224,224) ## img resize\n",
    "    img = norm1(img) ## 정규화\n",
    "    img = np.dstack([img])\n",
    "    label = to_categorical(1, num_classes=2)\n",
    "    valid_data.append(img)\n",
    "    valid_labels.append(label)\n",
    "    \n",
    "# Convert the list into numpy arrays\n",
    "valid_data = np.array(valid_data)\n",
    "valid_labels = np.array(valid_labels)\n",
    "print(\"image 2 \", valid_data[1].shape)\n",
    "\n",
    "print(\"Total number of validation examples: \", valid_data.shape)\n",
    "print(\"Total number of labels:\", valid_labels.shape)\n",
    "\n",
    "\n",
    "def data_gen(data, batch_size, img_size):\n",
    "    n = len(data)\n",
    "    steps = n//batch_size\n",
    "    \n",
    "    \n",
    "    batch_data = np.zeros((batch_size,img_size[0],img_size[1],1), dtype=np.float32)\n",
    "    batch_labels =np.zeros((batch_size,2), dtype=np.float32) ## 수정필요\n",
    "    \n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    i = 0\n",
    "    while True:\n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            img_name = data.iloc[idx]['image']\n",
    "            label = data.iloc[idx]['label']\n",
    "            \n",
    "            encoded_label = to_categorical(label, num_classes=2) ## 수정 필요\n",
    "            \n",
    "            img = cv2.imread(str(img_name), cv2.IMREAD_GRAYSCALE)\n",
    "            img = distinction3(img) ## 선명도 높이기\n",
    "            img = img_resize3(img,img_size[1],img_size[0]) ## img resize\n",
    "            img = norm1(img) ## 정규화\n",
    "            img = np.dstack([img]) ## 차원 맞추기\n",
    "            batch_data[count] = img\n",
    "            batch_labels[count] = encoded_label\n",
    "            \n",
    "            count +=1\n",
    "            if count==batch_size -1:\n",
    "                break\n",
    "        i += 1\n",
    "        yield batch_data, batch_labels\n",
    "        \n",
    "        if i>=steps:\n",
    "            i=0\n",
    "            np.random.shuffle(indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
