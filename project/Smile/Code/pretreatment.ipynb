{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9378c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from pathlib import Path\n",
    "import imgaug as aug\n",
    "import imgaug.augmenters as iaa\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481279b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 10598821597361201043\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 4158062592\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 3165428866256264187\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ae1122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s_ex9845\\AppData\\Local\\Temp/ipykernel_12052/337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a4179d",
   "metadata": {},
   "source": [
    "# 데이터 처리 순서\n",
    "1. 히스토그램 추출 (배경과 x-ray 차이가 많이 날때 즉 x-ray histogram이 한곳에 몰려있을때)\n",
    "2. 주파수별 가중치 부여 (히스토그램 추출 할때 고주파 영역이 너무 부자연스러운 경우가 있음 이를조정)\n",
    "3. 밝기 조절( he , clahe, custom)\n",
    "4. resize\n",
    "5. normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d139cfd7",
   "metadata": {},
   "source": [
    "# Data 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f06740",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('D:\\\\Data\\\\SMILE\\\\chest_xray')\n",
    "test = data_path / 'test'\n",
    "train = data_path / 'train'\n",
    "val = data_path / 'val'\n",
    "\n",
    "test_normal = test/ 'NORMAL'\n",
    "test_pneumonia = test/ 'PNEUMONIA'\n",
    "\n",
    "train_normal = train/ 'NORMAL'\n",
    "train_pneumonia = train/ 'PNEUMONIA'\n",
    "\n",
    "val_normal = val/ 'NORMAL'\n",
    "val_pneumonia = val/ 'PNEUMONIA'\n",
    "\n",
    "\n",
    "\n",
    "ex_img = train_normal/'IM-0115-0001.jpeg'\n",
    "Leena = data_path/'Lenna.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d0471",
   "metadata": {},
   "source": [
    "# 이미지 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc101ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(str(ex_img), cv2.IMREAD_UNCHANGED)  ## 우선은 기존 사진을 불러오는게 맞을듯\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95425b8e",
   "metadata": {},
   "source": [
    "# 이미지 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d346124a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "(1858, 2090)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14436e0e370>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(img.dtype) ##bit 수확인\n",
    "print(img.shape)\n",
    "hist = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "plt.plot(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8714da45",
   "metadata": {},
   "source": [
    "# 이미지 선명도 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ddff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinction1(img): #clahe girdsize가 크면 클수록 대비가 좋아지긴하나 부자연스러움\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize = (8,8)) \n",
    "    return clahe.apply(img)\n",
    "\n",
    "def distinction2(img): # 히스토그램 평활화\n",
    "    return cv2.equalizeHist(img)\n",
    "\n",
    "def distinction3(img): # 고주파 영역 clahe 영향 키우고 저주파영역 he영향 키움 clahe 자연스럽게 만든거라 생각 하면됨\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize = (8,8)) \n",
    "    clahe_img = clahe.apply(img)\n",
    "    he_img = cv2.equalizeHist(img)\n",
    "    std = img.std()\n",
    "    for dh in range(0,img.shape[0]-7,8):\n",
    "        for dw in range(0,img.shape[1]-7,8):\n",
    "            crop = img[dh:dh+8,dw:dw+8]\n",
    "            if std >= crop.std(): #상대적으로 저주파 지역\n",
    "                img[dh:dh+8,dw:dw+8] = clahe_img[dh:dh+8,dw:dw+8]\n",
    "            else:\n",
    "                img[dh:dh+8,dw:dw+8] = he_img[dh:dh+8,dw:dw+8]\n",
    "    return img\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a4c2348",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_img = img.copy()\n",
    "cv2.imshow('img', f_img)\n",
    "cv2.imshow('img1', distinction1(f_img))\n",
    "cv2.imshow('img2', distinction2(f_img))\n",
    "cv2.imshow('img3', distinction3(f_img))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661aadf0",
   "metadata": {},
   "source": [
    "# 주파수 영역 출출 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0454b251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115, 1254)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(str(ex_img), cv2.IMREAD_UNCHANGED)  ## 우선은 기존 사진을 불러오는게 맞을듯\n",
    "f_img = img.copy()\n",
    "f_img = cv2.resize(f_img ,dsize=(0,0),fx=0.6,fy=0.6, interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('img', f_img)\n",
    "\n",
    "height ,width = f_img.shape\n",
    "crow , ccol = int(height/2), int(width/2)\n",
    "dh, dw = int(height/20), int(width/20)\n",
    "\n",
    "img_zip = []\n",
    "for i in range(1,11):\n",
    "        \n",
    "    background = np.zeros((height, width),dtype= int)\n",
    "    f = np.fft.fft2(f_img)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    fshift2 = fshift.copy()\n",
    "    if i == 1:\n",
    "        fshift[crow-(dh*i):crow+(dh*i),ccol-(dw*i):ccol+(dw*i)] = 0\n",
    "        fshift2 = fshift2 - fshift\n",
    "    elif i ==10:\n",
    "        fshift[crow-(dh*(i-1)):crow+(dh*(i-1)),ccol-(dh*(i-1)):ccol+(dh*(i-1))] = 0\n",
    "        fshift2 = fshift2 - fshift\n",
    "    else: \n",
    "        fshift[crow-dh*(i-1):crow+dh*(i-1),ccol-dw*(i-1):ccol+dw*(i-1)] = 0\n",
    "        fshift2[crow-(dh*i):crow+(dh*i),ccol-(dw*i):ccol+(dw*i)] = 0\n",
    "        fshift2 = fshift -  fshift2\n",
    "    f_ishift = np.fft.ifftshift(fshift2)\n",
    "    img_back = np.fft.ifft2(f_ishift)\n",
    "    img_back = np.abs(img_back)\n",
    "    img_zip.append(img_back)\n",
    "    \n",
    "weight_img = np.zeros(f_img.shape, np.float32 )\n",
    "print(weight_img.shape)\n",
    "for i, _img in enumerate(img_zip):\n",
    "    if i <3 :\n",
    "        weight_img = weight_img + 1.2*_img\n",
    "    elif (i>=3)and(i<7):\n",
    "        weight_img = weight_img + 1.8*_img\n",
    "    else:\n",
    "        weight_img = weight_img + 0.6*_img\n",
    "        \n",
    "weight_img = weight_img.astype('uint8')\n",
    "cv2.imshow('weight_img', weight_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c2df23",
   "metadata": {},
   "source": [
    "# image resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93aba818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_resize1(img,w,h):  # padding을 통해 size 맞춤\n",
    "    if((w/img.shape[1]) < h/img.shape[0]):\n",
    "        percent = w/img.shape[1]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_LINEAR)\n",
    "        dh = (h-img.shape[0])/2\n",
    "        M = np.array([[1,0,0],[0,1,dh]],dtype=np.float64)  \n",
    "        img = cv2.warpAffine(img, M, (w, h))\n",
    "    else:\n",
    "        percent = h/img.shape[0]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_LINEAR)\n",
    "        dw = (w-img.shape[1])/2\n",
    "        M = np.array([[1,0,dw],[0,1,0]],dtype=np.float64)  \n",
    "        img = cv2.warpAffine(img, M, (w, h))\n",
    "    return img\n",
    "        \n",
    "def img_resize2(img,w,h): #crop을 통해 size 맞춤\n",
    "    if((w/img.shape[1]) > h/img.shape[0]):\n",
    "        percent = w/img.shape[1]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_LINEAR)\n",
    "        print(\"1\",img.shape[0])\n",
    "        dh = (img.shape[0]-h)//2\n",
    "        img = img[dh:dh+h,:].copy()\n",
    "    else:\n",
    "        percent = h/img.shape[0]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_LINEAR)\n",
    "        print(\"2\",img.shape[1])\n",
    "        dw = (img.shape[1]-w)//2\n",
    "        img = img[:,dw:dw+w].copy()\n",
    "    return img\n",
    "    \n",
    "def img_resize3(img,w,h):  # resize1과 동일 보간법 차이\n",
    "    if((w/img.shape[1]) < h/img.shape[0]):\n",
    "        percent = w/img.shape[1]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_AREA)\n",
    "        dh = (h-img.shape[0])/2\n",
    "        M = np.array([[1,0,0],[0,1,dh]],dtype=np.float64)  \n",
    "        img = cv2.warpAffine(img, M, (w, h))\n",
    "    else:\n",
    "        percent = h/img.shape[0]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_AREA)\n",
    "        dw = (w-img.shape[1])/2\n",
    "        M = np.array([[1,0,dw],[0,1,0]],dtype=np.float64)  \n",
    "        img = cv2.warpAffine(img, M, (w, h))\n",
    "    return img\n",
    "        \n",
    "def img_resize4(img,w,h): #resize2과 동일 보간법 차이\n",
    "    if((w/img.shape[1]) > h/img.shape[0]):\n",
    "        percent = w/img.shape[1]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_AREA)\n",
    "        print(\"1\",img.shape[0])\n",
    "        dh = (img.shape[0]-h)//2\n",
    "        img = img[dh:dh+h,:].copy()\n",
    "    else:\n",
    "        percent = h/img.shape[0]\n",
    "        img = cv2.resize(img,dsize=(0,0),fx=percent,fy=percent, interpolation = cv2.INTER_AREA)\n",
    "        print(\"2\",img.shape[1])\n",
    "        dw = (img.shape[1]-w)//2\n",
    "        img = img[:,dw:dw+w].copy()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16720d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 600)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "f_img = img.copy()\n",
    "cv2.imshow('before', f_img)\n",
    "f_img1 = img_resize1(f_img,600,500)\n",
    "f_img2 = img_resize3(f_img,600,500)\n",
    "print(f_img2.shape)\n",
    "cv2.imshow('after1', f_img1)\n",
    "cv2.imshow('after2', f_img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e6eed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 533\n"
     ]
    }
   ],
   "source": [
    "f_img = img.copy()\n",
    "f_img2 = img_resize2(f_img,600,500)\n",
    "cv2.imshow('img', f_img2)\n",
    "cv2.imshow('img1', distinction1(f_img2))\n",
    "cv2.imshow('img2', distinction2(f_img2))\n",
    "cv2.imshow('img3', distinction3(f_img2))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992012e6",
   "metadata": {},
   "source": [
    "# normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80caf6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm1(img):\n",
    "    img = (img.astype(np.float32)-img.min())/(img.max()-img.min())\n",
    "    return img\n",
    "\n",
    "def norm2(img):\n",
    "    img = (img.astype(np.float32) - img.mean())/(img.std())\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b55f96a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3.980e+02, 1.459e+03, 1.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         0.000e+00],\n",
       "        [4.130e+02, 1.443e+03, 2.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         0.000e+00],\n",
       "        [4.100e+02, 1.446e+03, 2.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         0.000e+00],\n",
       "        ...,\n",
       "        [1.098e+03, 4.970e+02, 1.410e+02, ..., 0.000e+00, 0.000e+00,\n",
       "         0.000e+00],\n",
       "        [1.084e+03, 5.180e+02, 1.370e+02, ..., 0.000e+00, 0.000e+00,\n",
       "         0.000e+00],\n",
       "        [1.092e+03, 5.150e+02, 1.350e+02, ..., 0.000e+00, 0.000e+00,\n",
       "         0.000e+00]]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ],\n",
       "       dtype=float32),\n",
       " <a list of 2090 BarContainer objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_img = img.copy()\n",
    "f_img = norm1(f_img)\n",
    "plt.hist(f_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5fb22c",
   "metadata": {},
   "source": [
    "# augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf1e02e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_seq =  iaa.Sequential([\n",
    "    iaa.Fliplr(), # horizontal flips\n",
    "    iaa.Affine(rotate=(20,60),\n",
    "               translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "              shear=(-16, 16)), # roatation\n",
    "    iaa.Multiply((1.2, 1.5))] #random brightness\n",
    "    ,random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ff824d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_img = train_normal/'IM-0115-0001.jpeg'\n",
    "ex_img = cv2.imread(str(ex_img), cv2.IMREAD_UNCHANGED)\n",
    "aug_img = aug_seq.augment_image(ex_img)\n",
    "cv2.imshow('aug_img', aug_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f39db4a",
   "metadata": {},
   "source": [
    "# Data generator1 (이미지 np.array 형태로 반환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c5272ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretreatment(path, class_id, per):\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "    for img in path:\n",
    "        img = cv2.imread(str(img), cv2.IMREAD_GRAYSCALE)\n",
    "        img = distinction3(img) ## 선명도 높이기\n",
    "        img = img_resize3(img,224,224) ## 수정 필요\n",
    "        \n",
    "        origin_img = norm1(img) ## 정규화 \n",
    "        origin_img = np.dstack([origin_img])\n",
    "        \n",
    "        label = to_categorical(class_id, num_classes=2) ## 수정 필요\n",
    "        \n",
    "        data.append(origin_img)\n",
    "        labels.append(label)\n",
    "        \n",
    "        for i in range(per):\n",
    "            aug_img = aug_seq.augment_image(img)\n",
    "            aug_img = norm1(aug_img)\n",
    "            aug_img = np.dstack([aug_img])\n",
    "            data.append(aug_img)\n",
    "            labels.append(label)\n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return data, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f135e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_cases = val_normal.glob('*.jpeg')\n",
    "pneumonia_cases = val_pneumonia.glob('*.jpeg')\n",
    "img, label = pretreatment(normal_cases, 0, 2)\n",
    "for i in range (0,len(img)):\n",
    "    cv2.imshow('aug_img' + str(i), img[i])\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d9a288",
   "metadata": {},
   "source": [
    "# Data generator2 (batch 단위 이미지 generator 반환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8e28b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data, batch_size, img_size):\n",
    "    n = len(data)\n",
    "    steps = n//batch_size\n",
    "    \n",
    "    \n",
    "    batch_data = np.zeros((batch_size,img_size[0],img_size[1],3), dtype=np.float32)\n",
    "    batch_labels =np.zeros((batch_size,2), dtype=np.float32) ## 수정필요\n",
    "    \n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    i = 0\n",
    "    while True:\n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            img_name = data.iloc[idx]['image']\n",
    "            label = data.iloc[idx]['label']\n",
    "            \n",
    "            encoded_label = to_categorical(label, num_classes=2) ## 수정 필요\n",
    "            \n",
    "            img = cv2.imread(str(img_name), cv2.IMREAD_GRAYSCALE)\n",
    "            img = distinction1(img) ## 선명도 높이기\n",
    "            img = img_resize3(img,img_size[1],img_size[0]) ## img resize\n",
    "            img = norm1(img) ## 정규화\n",
    "            img = np.dstack([img,img,img]) ## 차원 맞추기\n",
    "            batch_data[count] = img\n",
    "            batch_labels[count] = encoded_label\n",
    "            \n",
    "            count +=1\n",
    "            if count==batch_size -1:\n",
    "                break\n",
    "        i += 1\n",
    "        yield batch_data, batch_labels\n",
    "        \n",
    "        if i>=steps:\n",
    "            i=0\n",
    "            np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4472ff76",
   "metadata": {},
   "source": [
    "# train  데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c4cfe1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm_cases = train_normal.glob('*.jpeg')\n",
    "pneumonia_cases = train_pneumonia.glob('*.jpeg')\n",
    "\n",
    "train_data = []\n",
    "for img in norm_cases:\n",
    "    train_data.append((img, 0))\n",
    "    \n",
    "for img in pneumonia_cases:\n",
    "    train_data.append((img, 1))\n",
    "\n",
    "train_data = pd.DataFrame(train_data, columns=['image', 'label'], index = None)\n",
    "train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "sns.countplot(x='label', data=train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b1b3bf",
   "metadata": {},
   "source": [
    "# validation 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6812d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 2  (224, 224, 3)\n",
      "Total number of validation examples:  (16, 224, 224, 3)\n",
      "Total number of labels: (16, 2)\n"
     ]
    }
   ],
   "source": [
    "# 배운점 \n",
    "    #os.listdir = 해당 디렉토리 파일명만 가져옴\n",
    "    #glob = 해당 디렉토리의 경로명까지 가져옴 ->내생각엔 사진을 불러오는 느낌이라기 보단 경로를 불러오는 느낌\n",
    "    #glob 은 generator를 반환함 \n",
    "    #dstack, stack, concatenate 차이 \n",
    "\n",
    "normal_cases = val_normal.glob('*.jpeg')\n",
    "pneumonia_cases = val_pneumonia.glob('*.jpeg')\n",
    "\n",
    "valid_data = []\n",
    "valid_labels = []\n",
    "\n",
    "for img in normal_cases:\n",
    "    img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)\n",
    "    img = distinction1(img) ## 선명도 높이기\n",
    "    img = img_resize3(img,224,224) ## img resize\n",
    "    img = norm1(img) ## 정규화 \n",
    "    img = np.dstack([img,img,img])\n",
    "    label = to_categorical(0, num_classes=2)\n",
    "    valid_data.append(img)\n",
    "    valid_labels.append(label)\n",
    "\n",
    "for img in pneumonia_cases:\n",
    "    img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)\n",
    "    img = distinction1(img) ## 선명도 높이기\n",
    "    img = img_resize3(img,224,224) ## img resize\n",
    "    img = norm1(img) ## 정규화\n",
    "    img = np.dstack([img,img,img])\n",
    "    label = to_categorical(1, num_classes=2)\n",
    "    valid_data.append(img)\n",
    "    valid_labels.append(label)\n",
    "    \n",
    "# Convert the list into numpy arrays\n",
    "valid_data = np.array(valid_data)\n",
    "valid_labels = np.array(valid_labels)\n",
    "print(\"image 2 \", valid_data[1].shape)\n",
    "\n",
    "print(\"Total number of validation examples: \", valid_data.shape)\n",
    "print(\"Total number of labels:\", valid_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfce9162",
   "metadata": {},
   "source": [
    "# Model 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a47edde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ImageInput (InputLayer)     [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " Conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " Conv2_1 (SeparableConv2D)   (None, 112, 112, 128)     8896      \n",
      "                                                                 \n",
      " Conv2_2 (SeparableConv2D)   (None, 112, 112, 128)     17664     \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " Conv3_1 (SeparableConv2D)   (None, 56, 56, 256)       34176     \n",
      "                                                                 \n",
      " bn1 (BatchNormalization)    (None, 56, 56, 256)       1024      \n",
      "                                                                 \n",
      " Conv3_2 (SeparableConv2D)   (None, 56, 56, 256)       68096     \n",
      "                                                                 \n",
      " bn2 (BatchNormalization)    (None, 56, 56, 256)       1024      \n",
      "                                                                 \n",
      " Conv3_3 (SeparableConv2D)   (None, 56, 56, 256)       68096     \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " Conv4_1 (SeparableConv2D)   (None, 28, 28, 512)       133888    \n",
      "                                                                 \n",
      " bn3 (BatchNormalization)    (None, 28, 28, 512)       2048      \n",
      "                                                                 \n",
      " Conv4_2 (SeparableConv2D)   (None, 28, 28, 512)       267264    \n",
      "                                                                 \n",
      " bn4 (BatchNormalization)    (None, 28, 28, 512)       2048      \n",
      "                                                                 \n",
      " Conv4_3 (SeparableConv2D)   (None, 28, 28, 512)       267264    \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 1024)              102761472 \n",
      "                                                                 \n",
      " dropout1 (Dropout)          (None, 1024)              0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout2 (Dropout)          (None, 512)               0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,197,506\n",
      "Trainable params: 104,194,434\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#배운점\n",
    "    #3*3 kernel 을 사용하면 왜 7*7 보다 파라미터가 줄어드는지\n",
    "    # adam 최적화 기법 : 관성과 변수별 학습률을 고려한 최적의 최적화기법\n",
    "    # relu singmoid -> 이진분류 identity -> 회귀\n",
    "    # batch normal -> \n",
    "    # 기울기 소실문제 합성 함수의 미분을 구하는것은 계속해서 곱해나간단 소린데 1보다작은수를 계속 곱해나가면 기울기가 계속 줄어듬\n",
    "    # ? 왜 모델이 깊어질수록 비선형성이 증가하는가\n",
    "    # ? 왜 channel을 점점 키우는 걸까 키우면 왜 보통 2배씩 커지지\n",
    "from keras.layers import BatchNormalization\n",
    "def build_model():\n",
    "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "    \n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c456dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import math\n",
    "\n",
    "class CosineAnnealingWarmup(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs_per_cycle,iteration, max_lr, min_lr, verbose = 1):\n",
    "        self.epochs_per_cycle = epochs_per_cycle\n",
    "        self.max_lr = max_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.iteration = iteration;\n",
    "        self.steps = 0;\n",
    "        self.learning_rate = max_lr;\n",
    "        self.epochs = 0; # epoch to search min_lr for each iteration \n",
    "        self.warmup_epoch = 10  # warmup epcch\n",
    "        self.verbose = verbose # log\n",
    "        self.lrates = list() # for graph\n",
    "        \n",
    "        \n",
    "    def cosine_annealing(self, epoch, epochs_per_cycle, max_lr):\n",
    "        self.epochs += 1; \n",
    "        cos_inner = (math.pi * (self.epochs % epochs_per_cycle)) / (epochs_per_cycle)\n",
    "        self.learning_rate = max_lr/2 * (math.cos(cos_inner) + 1)\n",
    "        \n",
    "        if ((self.epochs % epochs_per_cycle) == (epochs_per_cycle-1)):\n",
    "            self.steps += 1\n",
    "            self.max_lr *= 0.8\n",
    "            self.epochs = 0;\n",
    "            self.epochs_per_cycle = math.floor(self.epochs_per_cycle*1.2)\n",
    "            \n",
    "        return max_lr/2 * (math.cos(cos_inner) + 1)\n",
    "  \n",
    "    def warm_up(self, epoch):\n",
    "        \n",
    "        self.learning_rate = self.max_lr * epoch / self.warmup_epoch\n",
    "        \n",
    "        return self.learning_rate\n",
    "\n",
    "    # calculate and set learning rate at the start of the epoch\n",
    "    def on_epoch_begin(self, epoch, logs = None):\n",
    "        if (epoch < self.warmup_epoch):\n",
    "            # warm up learning rate\n",
    "            lr = self.warm_up(epoch)\n",
    "       \n",
    "        elif(self.steps < self.iteration):\n",
    "            # calculate learning rate\n",
    "            lr = self.cosine_annealing(epoch, self.epochs_per_cycle, self.max_lr)\n",
    "            \n",
    "        else:\n",
    "            lr = self.min_lr\n",
    "        \n",
    "        if (self.verbose == 1):\n",
    "            print('\\nEpoch %05d: CosineAnnealingScheduler setting learng rate to %s.' % (epoch + 1, lr))  \n",
    "\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "        self.lrates.append(lr)\n",
    "        \n",
    "cosine_schedule = CosineAnnealingWarmup(epochs_per_cycle=50, iteration=3, max_lr = 1e-3, min_lr = 1e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e970bf9",
   "metadata": {},
   "source": [
    "# Model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e10b199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training and validation steps: 326 and 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_ex9845\\AppData\\Local\\Temp/ipykernel_12052/3952781319.py:25: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_data_gen, epochs=nb_epochs,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: CosineAnnealingScheduler setting learng rate to 0.0.\n",
      "Epoch 1/200\n",
      "  6/326 [..............................] - ETA: 1:06 - loss: 0.4202 - accuracy: 0.5521WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0567s vs `on_train_batch_end` time: 0.1255s). Check your callbacks.\n",
      "326/326 [==============================] - 74s 219ms/step - loss: 0.4046 - accuracy: 0.3100 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: CosineAnnealingScheduler setting learng rate to 0.0001.\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 71s 217ms/step - loss: 0.4020 - accuracy: 0.6618 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: CosineAnnealingScheduler setting learng rate to 0.0002.\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 71s 217ms/step - loss: 0.4036 - accuracy: 0.6789 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00004: CosineAnnealingScheduler setting learng rate to 0.00030000000000000003.\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 70s 215ms/step - loss: 0.4029 - accuracy: 0.6977 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00005: CosineAnnealingScheduler setting learng rate to 0.0004.\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 70s 215ms/step - loss: 0.4020 - accuracy: 0.6996 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00006: CosineAnnealingScheduler setting learng rate to 0.0005.\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 71s 217ms/step - loss: 0.4031 - accuracy: 0.6823 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00007: CosineAnnealingScheduler setting learng rate to 0.0006000000000000001.\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 71s 216ms/step - loss: 0.4034 - accuracy: 0.6936 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00008: CosineAnnealingScheduler setting learng rate to 0.0007.\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 70s 216ms/step - loss: 0.4027 - accuracy: 0.6764 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00009: CosineAnnealingScheduler setting learng rate to 0.0008.\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 71s 217ms/step - loss: 0.4033 - accuracy: 0.6557 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00010: CosineAnnealingScheduler setting learng rate to 0.0009000000000000001.\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 70s 216ms/step - loss: 0.4030 - accuracy: 0.6965 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00011: CosineAnnealingScheduler setting learng rate to 0.0009990133642141358.\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 70s 216ms/step - loss: 0.4032 - accuracy: 0.6959 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00012: CosineAnnealingScheduler setting learng rate to 0.000996057350657239.\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.4023 - accuracy: 0.6980 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00013: CosineAnnealingScheduler setting learng rate to 0.0009911436253643444.\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.4032 - accuracy: 0.6286 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00014: CosineAnnealingScheduler setting learng rate to 0.0009842915805643156.\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.4020 - accuracy: 0.6990 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00015: CosineAnnealingScheduler setting learng rate to 0.0009755282581475768.\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 70s 213ms/step - loss: 0.4032 - accuracy: 0.6963 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00016: CosineAnnealingScheduler setting learng rate to 0.0009648882429441257.\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 70s 213ms/step - loss: 0.4041 - accuracy: 0.6925 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00017: CosineAnnealingScheduler setting learng rate to 0.0009524135262330098.\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.4030 - accuracy: 0.6967 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00018: CosineAnnealingScheduler setting learng rate to 0.0009381533400219318.\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.4024 - accuracy: 0.6739 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00019: CosineAnnealingScheduler setting learng rate to 0.0009221639627510075.\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.4042 - accuracy: 0.6829 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00020: CosineAnnealingScheduler setting learng rate to 0.0009045084971874737.\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.4031 - accuracy: 0.6881 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00021: CosineAnnealingScheduler setting learng rate to 0.0008852566213878947.\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 70s 216ms/step - loss: 0.4027 - accuracy: 0.6977 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00022: CosineAnnealingScheduler setting learng rate to 0.0008644843137107057.\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 70s 213ms/step - loss: 0.4034 - accuracy: 0.6643 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00023: CosineAnnealingScheduler setting learng rate to 0.0008422735529643444.\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 69s 213ms/step - loss: 0.4035 - accuracy: 0.6735 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00024: CosineAnnealingScheduler setting learng rate to 0.0008187119948743449.\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 69s 213ms/step - loss: 0.4026 - accuracy: 0.6979 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00025: CosineAnnealingScheduler setting learng rate to 0.0007938926261462367.\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 70s 213ms/step - loss: 0.4030 - accuracy: 0.6526 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00026: CosineAnnealingScheduler setting learng rate to 0.0007679133974894983.\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.4042 - accuracy: 0.6601 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00027: CosineAnnealingScheduler setting learng rate to 0.0007408768370508576.\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.4020 - accuracy: 0.6898 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00028: CosineAnnealingScheduler setting learng rate to 0.0007128896457825364.\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 69s 213ms/step - loss: 0.4034 - accuracy: 0.6748 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00029: CosineAnnealingScheduler setting learng rate to 0.0006840622763423391.\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.4046 - accuracy: 0.6457 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00030: CosineAnnealingScheduler setting learng rate to 0.0006545084971874737.\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.4034 - accuracy: 0.6877 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00031: CosineAnnealingScheduler setting learng rate to 0.0006243449435824273.\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 69s 213ms/step - loss: 0.4028 - accuracy: 0.6975 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00032: CosineAnnealingScheduler setting learng rate to 0.0005936906572928624.\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.4034 - accuracy: 0.6536 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00033: CosineAnnealingScheduler setting learng rate to 0.0005626666167821522.\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.4030 - accuracy: 0.6973 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00034: CosineAnnealingScheduler setting learng rate to 0.0005313952597646568.\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.4039 - accuracy: 0.6570 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00035: CosineAnnealingScheduler setting learng rate to 0.0005.\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 16162s 50s/step - loss: 0.4022 - accuracy: 0.6992 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00036: CosineAnnealingScheduler setting learng rate to 0.0004686047402353433.\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 71s 217ms/step - loss: 0.4033 - accuracy: 0.6965 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00037: CosineAnnealingScheduler setting learng rate to 0.00043733338321784795.\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 71s 217ms/step - loss: 0.4025 - accuracy: 0.6833 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00038: CosineAnnealingScheduler setting learng rate to 0.0004063093427071377.\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 71s 216ms/step - loss: 0.4028 - accuracy: 0.6950 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00039: CosineAnnealingScheduler setting learng rate to 0.00037565505641757257.\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 71s 217ms/step - loss: 0.4032 - accuracy: 0.6917 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00040: CosineAnnealingScheduler setting learng rate to 0.00034549150281252644.\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 71s 217ms/step - loss: 0.4031 - accuracy: 0.6971 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00041: CosineAnnealingScheduler setting learng rate to 0.00031593772365766116.\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 71s 218ms/step - loss: 0.4025 - accuracy: 0.6660 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00042: CosineAnnealingScheduler setting learng rate to 0.00028711035421746366.\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 71s 217ms/step - loss: 0.4034 - accuracy: 0.6831 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00043: CosineAnnealingScheduler setting learng rate to 0.0002591231629491423.\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 71s 217ms/step - loss: 0.4035 - accuracy: 0.6662 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00044: CosineAnnealingScheduler setting learng rate to 0.00023208660251050156.\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 71s 217ms/step - loss: 0.4036 - accuracy: 0.6959 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00045: CosineAnnealingScheduler setting learng rate to 0.00020610737385376348.\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 70s 216ms/step - loss: 0.4042 - accuracy: 0.6551 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00046: CosineAnnealingScheduler setting learng rate to 0.00018128800512565513.\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 70s 216ms/step - loss: 0.4033 - accuracy: 0.6967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00047: CosineAnnealingScheduler setting learng rate to 0.00015772644703565563.\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 70s 216ms/step - loss: 0.4031 - accuracy: 0.6812 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00048: CosineAnnealingScheduler setting learng rate to 0.00013551568628929433.\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 71s 218ms/step - loss: 0.4039 - accuracy: 0.6300 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00049: CosineAnnealingScheduler setting learng rate to 0.00011474337861210544.\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 71s 218ms/step - loss: 0.4036 - accuracy: 0.6290 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00050: CosineAnnealingScheduler setting learng rate to 9.549150281252633e-05.\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 71s 216ms/step - loss: 0.4036 - accuracy: 0.6808 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00051: CosineAnnealingScheduler setting learng rate to 7.783603724899258e-05.\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.4034 - accuracy: 0.6913 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00052: CosineAnnealingScheduler setting learng rate to 6.184665997806821e-05.\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 70s 215ms/step - loss: 0.4034 - accuracy: 0.6967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00053: CosineAnnealingScheduler setting learng rate to 4.758647376699032e-05.\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 70s 216ms/step - loss: 0.4040 - accuracy: 0.6952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00054: CosineAnnealingScheduler setting learng rate to 3.5111757055874326e-05.\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 70s 215ms/step - loss: 0.4035 - accuracy: 0.6263 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00055: CosineAnnealingScheduler setting learng rate to 2.4471741852423235e-05.\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 70s 216ms/step - loss: 0.4037 - accuracy: 0.6959 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00056: CosineAnnealingScheduler setting learng rate to 1.5708419435684518e-05.\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.4036 - accuracy: 0.6963 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00057: CosineAnnealingScheduler setting learng rate to 8.856374635655639e-06.\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.4044 - accuracy: 0.6793 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00058: CosineAnnealingScheduler setting learng rate to 3.942649342761117e-06.\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.4044 - accuracy: 0.6687 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00059: CosineAnnealingScheduler setting learng rate to 9.866357858642206e-07.\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.4039 - accuracy: 0.6499 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00060: CosineAnnealingScheduler setting learng rate to 0.0007994518139018296.\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.4042 - accuracy: 0.6919 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00061: CosineAnnealingScheduler setting learng rate to 0.0007978087581473094.\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 70s 215ms/step - loss: 0.4024 - accuracy: 0.6921 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00062: CosineAnnealingScheduler setting learng rate to 0.0007950753362380551.\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.4024 - accuracy: 0.6883 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00063: CosineAnnealingScheduler setting learng rate to 0.0007912590402935223.\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.4037 - accuracy: 0.6956 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00064: CosineAnnealingScheduler setting learng rate to 0.0007863703305156273.\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 70s 215ms/step - loss: 0.4043 - accuracy: 0.6637 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00065: CosineAnnealingScheduler setting learng rate to 0.0007804226065180615.\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 69s 213ms/step - loss: 0.4037 - accuracy: 0.6666 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00066: CosineAnnealingScheduler setting learng rate to 0.0007734321705988807.\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 70s 215ms/step - loss: 0.4038 - accuracy: 0.6837 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00067: CosineAnnealingScheduler setting learng rate to 0.0007654181830570404.\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 21001s 65s/step - loss: 0.4030 - accuracy: 0.6971 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00068: CosineAnnealingScheduler setting learng rate to 0.0007564026096753472.\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 72s 222ms/step - loss: 0.4034 - accuracy: 0.6839 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00069: CosineAnnealingScheduler setting learng rate to 0.0007464101615137755.\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 72s 222ms/step - loss: 0.4034 - accuracy: 0.6601 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00070: CosineAnnealingScheduler setting learng rate to 0.0007354682271781697.\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 74s 226ms/step - loss: 0.4042 - accuracy: 0.6731 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00071: CosineAnnealingScheduler setting learng rate to 0.000723606797749979.\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 74s 226ms/step - loss: 0.4040 - accuracy: 0.6948 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00072: CosineAnnealingScheduler setting learng rate to 0.0007108583845827884.\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 71s 217ms/step - loss: 0.4034 - accuracy: 0.6724 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00073: CosineAnnealingScheduler setting learng rate to 0.0006972579301909577.\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.4040 - accuracy: 0.6158 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00074: CosineAnnealingScheduler setting learng rate to 0.0006828427124746191.\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 73s 224ms/step - loss: 0.4028 - accuracy: 0.6977 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00075: CosineAnnealingScheduler setting learng rate to 0.0006676522425435433.\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 72s 220ms/step - loss: 0.4026 - accuracy: 0.6980 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00076: CosineAnnealingScheduler setting learng rate to 0.000651728156419935.\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 70s 215ms/step - loss: 0.4016 - accuracy: 0.7005 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00077: CosineAnnealingScheduler setting learng rate to 0.0006351141009169893.\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 74s 226ms/step - loss: 0.4038 - accuracy: 0.6952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00078: CosineAnnealingScheduler setting learng rate to 0.0006178556140060109.\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.4035 - accuracy: 0.6892 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00079: CosineAnnealingScheduler setting learng rate to 0.0006000000000000001.\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 74s 227ms/step - loss: 0.4033 - accuracy: 0.6839 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00080: CosineAnnealingScheduler setting learng rate to 0.0005815961998958187.\n",
      "Epoch 80/200\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.4043 - accuracy: 0.6942 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00081: CosineAnnealingScheduler setting learng rate to 0.0005626946572303202.\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 73s 223ms/step - loss: 0.4028 - accuracy: 0.6764 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00082: CosineAnnealingScheduler setting learng rate to 0.0005433471798181203.\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.4037 - accuracy: 0.6798 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00083: CosineAnnealingScheduler setting learng rate to 0.0005236067977499791.\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 72s 221ms/step - loss: 0.4038 - accuracy: 0.6954 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00084: CosineAnnealingScheduler setting learng rate to 0.0005035276180410083.\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 72s 220ms/step - loss: 0.4032 - accuracy: 0.6969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00085: CosineAnnealingScheduler setting learng rate to 0.0004831646763271037.\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 73s 224ms/step - loss: 0.4027 - accuracy: 0.6793 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00086: CosineAnnealingScheduler setting learng rate to 0.0004625737860160924.\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 72s 220ms/step - loss: 0.4038 - accuracy: 0.6750 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00087: CosineAnnealingScheduler setting learng rate to 0.00044181138530706145.\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 72s 220ms/step - loss: 0.4036 - accuracy: 0.6622 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00088: CosineAnnealingScheduler setting learng rate to 0.0004209343824971775.\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 71s 218ms/step - loss: 0.4042 - accuracy: 0.6321 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00089: CosineAnnealingScheduler setting learng rate to 0.00040000000000000013.\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 73s 223ms/step - loss: 0.4038 - accuracy: 0.6816 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00090: CosineAnnealingScheduler setting learng rate to 0.0003790656175028226.\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 72s 220ms/step - loss: 0.4029 - accuracy: 0.6823 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00091: CosineAnnealingScheduler setting learng rate to 0.0003581886146929387.\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 72s 222ms/step - loss: 0.4026 - accuracy: 0.6578 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00092: CosineAnnealingScheduler setting learng rate to 0.0003374262139839077.\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 74s 226ms/step - loss: 0.4045 - accuracy: 0.6919 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00093: CosineAnnealingScheduler setting learng rate to 0.0003168353236728963.\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 75s 229ms/step - loss: 0.4034 - accuracy: 0.6539 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00094: CosineAnnealingScheduler setting learng rate to 0.00029647238195899177.\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 74s 227ms/step - loss: 0.4031 - accuracy: 0.6835 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00095: CosineAnnealingScheduler setting learng rate to 0.0002763932022500211.\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 73s 223ms/step - loss: 0.4031 - accuracy: 0.6973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00096: CosineAnnealingScheduler setting learng rate to 0.0002566528201818799.\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 72s 220ms/step - loss: 0.4033 - accuracy: 0.6967 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00097: CosineAnnealingScheduler setting learng rate to 0.00023730534276967995.\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 72s 221ms/step - loss: 0.4036 - accuracy: 0.6959 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00098: CosineAnnealingScheduler setting learng rate to 0.0002184038001041813.\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 72s 221ms/step - loss: 0.4026 - accuracy: 0.6888 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00099: CosineAnnealingScheduler setting learng rate to 0.0002000000000000001.\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 73s 224ms/step - loss: 0.4028 - accuracy: 0.6624 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00100: CosineAnnealingScheduler setting learng rate to 0.00018214438599398932.\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 72s 219ms/step - loss: 0.4029 - accuracy: 0.6977 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00101: CosineAnnealingScheduler setting learng rate to 0.0001648858990830108.\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 73s 223ms/step - loss: 0.4030 - accuracy: 0.6768 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00102: CosineAnnealingScheduler setting learng rate to 0.0001482718435800651.\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 72s 221ms/step - loss: 0.4031 - accuracy: 0.6973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00103: CosineAnnealingScheduler setting learng rate to 0.00013234775745645685.\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 72s 222ms/step - loss: 0.4029 - accuracy: 0.6860 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00104: CosineAnnealingScheduler setting learng rate to 0.00011715728752538102.\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 72s 221ms/step - loss: 0.4030 - accuracy: 0.6975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00105: CosineAnnealingScheduler setting learng rate to 0.00010274206980904235.\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 72s 222ms/step - loss: 0.4045 - accuracy: 0.6821 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00106: CosineAnnealingScheduler setting learng rate to 8.914161541721165e-05.\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 71s 218ms/step - loss: 0.4034 - accuracy: 0.6837 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00107: CosineAnnealingScheduler setting learng rate to 7.639320225002106e-05.\n",
      "Epoch 107/200\n",
      "255/326 [======================>.......] - ETA: 15s - loss: 0.4037 - accuracy: 0.6517"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12052/3952781319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of training and validation steps: {} and {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_train_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m history = model.fit_generator(train_data_gen, epochs=nb_epochs, \n\u001b[0m\u001b[0;32m     26\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_train_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[1;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2015\u001b[0m         stacklevel=2)\n\u001b[1;32m-> 2016\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   2017\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m       raise ValueError(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    548\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \"\"\"\n\u001b[0;32m   1148\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\YOLO\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#배우점 \n",
    "    # keras 함수가 다함\n",
    "    # model (compile, fit_generator) , earlystopping, modelcheckpoint\n",
    "    #fit fit_generator 차이 \n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "model_folder = 'C:\\\\Users\\\\s_ex9845\\\\model\\\\vgg16'\n",
    "model_path = model_folder + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "opt = tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.05)\n",
    "es = EarlyStopping(monitor = 'val_accuracy', mode = 'max', patience=200, restore_best_weights=True)\n",
    "chkpt = ModelCheckpoint(model_path, monitor = 'val_accuracy', save_best_only=False)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer=opt)\n",
    "batch_size = 16\n",
    "nb_epochs = 200\n",
    "size = [224,224]\n",
    "# Get a train data generator\n",
    "train_data_gen = data_gen(data=train_data, batch_size=batch_size ,img_size = size)\n",
    "\n",
    "# Define the number of training steps\n",
    "nb_train_steps = train_data.shape[0]//batch_size\n",
    "\n",
    "print(\"Number of training and validation steps: {} and {}\".format(nb_train_steps, len(valid_data)))\n",
    "history = model.fit_generator(train_data_gen, epochs=nb_epochs, \n",
    "                              steps_per_epoch=nb_train_steps,\n",
    "                              validation_data=(valid_data, valid_labels),\n",
    "                              callbacks=[es, chkpt,cosine_schedule],\n",
    "                              class_weight={0:1.0, 1:0.4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f885fee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test examples:  (624, 224, 224, 3)\n",
      "Total number of labels: (624, 2)\n",
      "39/39 [==============================] - 2s 38ms/step - loss: 2.2536 - accuracy: 0.7179\n",
      "Loss on test set:  2.2536144256591797\n",
      "Accuracy on test set:  0.7179487347602844\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_normal = test/ 'NORMAL'\n",
    "test_pneumonia = test/ 'PNEUMONIA'\n",
    "\n",
    "normal_cases = test_normal.glob('*.jpeg')\n",
    "pneumonia_cases = test_pneumonia.glob('*.jpeg')\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for img in normal_cases:\n",
    "    img = cv2.imread(str(img), cv2.IMREAD_GRAYSCALE)\n",
    "    img = distinction1(img) ## 선명도 높이기\n",
    "    img = img_resize3(img,224,224) ## 수정 필요\n",
    "    origin_img = norm1(img) ## 정규화 \n",
    "    origin_img = np.dstack([origin_img,origin_img,origin_img])    \n",
    "    label = to_categorical(0, num_classes=2) ## 수정 필요\n",
    "    \n",
    "    test_data.append(origin_img)\n",
    "    test_labels.append(label)\n",
    "    \n",
    "for img in pneumonia_cases:\n",
    "    img = cv2.imread(str(img), cv2.IMREAD_GRAYSCALE)\n",
    "    img = distinction1(img) ## 선명도 높이기\n",
    "    img = img_resize3(img,224,224) ## 수정 필요\n",
    "    origin_img = norm1(img) ## 정규화 \n",
    "    origin_img = np.dstack([origin_img,origin_img,origin_img])    \n",
    "    label = to_categorical(1, num_classes=2) ## 수정 필요\n",
    "    \n",
    "    test_data.append(origin_img)\n",
    "    test_labels.append(label)\n",
    "    \n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(\"Total number of test examples: \", test_data.shape)\n",
    "print(\"Total number of labels:\", test_labels.shape)\n",
    "\n",
    "test_loss, test_score = model.evaluate(test_data, test_labels, batch_size=16)\n",
    "print(\"Loss on test set: \", test_loss)\n",
    "print(\"Accuracy on test set: \", test_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccec30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_seq =  iaa.OneOf([\n",
    "    iaa.Fliplr(), # horizontal flips\n",
    "    iaa.Affine(rotate=(20,60)\n",
    "               translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "              shear=(-16, 16)), # roatation\n",
    "    iaa.Multiply((1.2, 1.5))] #random brightness\n",
    "    ,random_order=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
