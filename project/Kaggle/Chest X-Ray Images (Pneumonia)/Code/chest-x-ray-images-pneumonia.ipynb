{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-14T11:42:22.524981Z","iopub.execute_input":"2021-11-14T11:42:22.525553Z","iopub.status.idle":"2021-11-14T11:42:22.547908Z","shell.execute_reply.started":"2021-11-14T11:42:22.525435Z","shell.execute_reply":"2021-11-14T11:42:22.547058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **import**","metadata":{}},{"cell_type":"code","source":"import os\nimport glob # 데이터 전처리 할때, 파일 불러올 때 사용\nimport h5py # 대용량의 데이터 빠르게 읽고 쓰기\nimport shutil\nimport imgaug as aug\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mimg\nimport imgaug.augmenters as iaa\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom PIL import Image\nfrom pathlib import Path\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom tensorflow.keras.optimizers import SGD\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nfrom keras import backend as K\ncolor = sns.color_palette()\n%matplotlib inline\n\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:24:49.104648Z","iopub.execute_input":"2021-11-14T12:24:49.104983Z","iopub.status.idle":"2021-11-14T12:24:58.461625Z","shell.execute_reply.started":"2021-11-14T12:24:49.104946Z","shell.execute_reply":"2021-11-14T12:24:58.460932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 데이터 불러오기","metadata":{}},{"cell_type":"code","source":"# 데이터 경로 지정\ndata_dir = Path('../input/chest-xray-pneumonia/chest_xray/chest_xray')\npath = '../input/chest-xray-pneumonia/chest_xray/chest_xray/train/NORMAL'\ntrain_dir = data_dir/'train'\nval_dir = data_dir/ 'val'\ntest_dir = data_dir/ 'test'\nnormal_cases_dir = train_dir / 'NORMAL'\npneumonia_cases_dir = train_dir / 'PNEUMONIA'\nnormal_cases = normal_cases_dir.glob('*.jpeg')\npneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n\n\n# train set 만들기\n\ntrain_data = []\nfor img in normal_cases:\n    print(img)\n    train_data.append((img, 0))\n    \nfor img in pneumonia_cases:\n    train_data.append((img, 1))\n\ntrain_data = pd.DataFrame(train_data, columns=['image', 'label'], index = None)\n\n# data shuffle ? 왜하는 거임\ntrain_data = train_data.sample(frac=1.).reset_index(drop=True)\n\ntrain_data.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:26:25.722197Z","iopub.execute_input":"2021-11-14T12:26:25.722505Z","iopub.status.idle":"2021-11-14T12:26:25.740557Z","shell.execute_reply.started":"2021-11-14T12:26:25.722472Z","shell.execute_reply":"2021-11-14T12:26:25.73925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#데이터 확인\ntrain_data[train_data['label']==1]\n\ncases_count = train_data['label'].value_counts()\nprint(cases_count)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:44:45.739246Z","iopub.execute_input":"2021-11-14T11:44:45.739558Z","iopub.status.idle":"2021-11-14T11:44:45.752366Z","shell.execute_reply.started":"2021-11-14T11:44:45.739532Z","shell.execute_reply":"2021-11-14T11:44:45.75158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 데이터 예시 보기","metadata":{}},{"cell_type":"code","source":"# 데이터 몇개 추출 \n# 배운점 \n    #to_list 역할 : dataframe 을 list로 변경해주어 for문 돌수있게 함\n    #loc iloc 차이 : loc은 값으로 원소에 접근하는거 iloc 은 index로 접근하는거\npneumonia_samples = (train_data[train_data['label']==1]['image'].iloc[:5]).tolist()\nnormal_samples = (train_data[train_data['label']==0]['image'].iloc[:5]).tolist()\n\nsamples = pneumonia_samples + normal_samples\ndel pneumonia_samples, normal_samples\n\nf, ax = plt.subplots(2,5, figsize=(30,10))\nfor i in range(10):\n    img = imread(samples[i])\n    ax[i//5, i%5].imshow(img, cmap='gray')\n    if i<5:\n        ax[i//5, i%5].set_title(\"Pneumonia\")\n    else:\n        ax[i//5, i%5].set_title(\"Normal\")\n    ax[i//5, i%5].axis('off')\n    ax[i//5, i%5].set_aspect('auto')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:44:55.322686Z","iopub.execute_input":"2021-11-14T11:44:55.323003Z","iopub.status.idle":"2021-11-14T11:44:58.197778Z","shell.execute_reply.started":"2021-11-14T11:44:55.32297Z","shell.execute_reply":"2021-11-14T11:44:58.195219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 배운점 \n    #os.listdir = 해당 디렉토리 파일명만 가져옴\n    #glob = 해당 디렉토리의 경로명까지 가져옴 ->내생각엔 사진을 불러오는 느낌이라기 보단 경로를 불러오는 느낌\n    #glob 은 generator를 반환함 \n    #dstack, stack, concatenate 차이 \nnormal_cases_dir = val_dir / 'NORMAL'\npneumonia_cases_dir = val_dir / 'PNEUMONIA'\n\nnormal_cases = normal_cases_dir.glob('*.jpeg')\npneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n\nvalid_data = []\nvalid_labels = []\n\nfor img in normal_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224)) ## 데이터 사이즈를 224로 줄여서 얻는 점 -> 크기 통일, 메모리 사용량 줄임 ?보통 몇으로 줄일까\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img]) # black 을 rgb로 즉 채널 1에서 3으로 확장\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255. #정규화 \n    label = to_categorical(0, num_classes=2)\n    valid_data.append(img)\n    valid_labels.append(label)\n\nfor img in pneumonia_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.\n    label = to_categorical(1, num_classes=2)\n    valid_data.append(img)\n    valid_labels.append(label)\n    \n# Convert the list into numpy arrays\nvalid_data = np.array(valid_data)\nvalid_labels = np.array(valid_labels)\n\nprint(\"Total number of validation examples: \", valid_data.shape)\nprint(\"Total number of labels:\", valid_labels.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:44:58.199262Z","iopub.execute_input":"2021-11-14T11:44:58.199793Z","iopub.status.idle":"2021-11-14T11:44:58.617508Z","shell.execute_reply.started":"2021-11-14T11:44:58.199759Z","shell.execute_reply":"2021-11-14T11:44:58.616582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq = iaa.OneOf([\n    iaa.Fliplr(), # horizontal flips\n    iaa.Affine(rotate=20), # roatation\n    iaa.Multiply((1.2, 1.5))]) #random brightness","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:44:58.61883Z","iopub.execute_input":"2021-11-14T11:44:58.619299Z","iopub.status.idle":"2021-11-14T11:44:58.625436Z","shell.execute_reply.started":"2021-11-14T11:44:58.619256Z","shell.execute_reply":"2021-11-14T11:44:58.624878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#배운점\n    # enumerate j, idx 로 for문 돌아야함 j = index idx = 값\n    #float32 타입으로 바꾼후 하는 거였음 255.도 주의\n    #data_generator드는게 전부네\ndef data_gen(data, batch_size):\n\n    n = len(data)\n    steps = n//batch_size\n    \n    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n    batch_labels = np.zeros((batch_size,2), dtype=np.float32)\n\n    indices = np.arange(n)\n    \n    i =0\n    while True:\n        np.random.shuffle(indices)\n        count = 0\n        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n        for j, idx in enumerate(next_batch): \n            img_name = data.iloc[idx]['image']\n            label = data.iloc[idx]['label']\n            \n            encoded_label = to_categorical(label, num_classes=2)\n            img = cv2.imread(str(img_name))\n            img = cv2.resize(img, (224,224))\n            \n            if img.shape[2]==1:\n                img = np.dstack([img, img, img])\n            \n            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            orig_img = img.astype(np.float32)/255. \n            \n            batch_data[count] = orig_img\n            batch_labels[count] = encoded_label\n            \n            #undersample 즉 sample 개수가 차이나니까 적은거 augment 해서 늘리는 거 같음\n            if label==0 and count < batch_size-2:\n                aug_img1 = seq.augment_image(img)\n                aug_img2 = seq.augment_image(img)\n                aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n                aug_img2 = cv2.cvtColor(aug_img2, cv2.COLOR_BGR2RGB)\n                aug_img1 = aug_img1.astype(np.float32)/255.\n                aug_img2 = aug_img2.astype(np.float32)/255.\n\n                batch_data[count+1] = aug_img1\n                batch_labels[count+1] = encoded_label\n                batch_data[count+2] = aug_img2\n                batch_labels[count+2] = encoded_label\n                count +=2 # 왜 3이 아니지?\n            \n            else:\n                count+=1\n            \n            if count==batch_size-1:\n                break\n            \n        i+=1\n        yield batch_data, batch_labels\n            \n        if i>=steps: #반복문은 언제 탈출? 탈출안함 그냥 계속 돌면서 죽을때까지 반환 \n            i=0","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:45:01.30345Z","iopub.execute_input":"2021-11-14T11:45:01.304133Z","iopub.status.idle":"2021-11-14T11:45:01.316173Z","shell.execute_reply.started":"2021-11-14T11:45:01.304075Z","shell.execute_reply":"2021-11-14T11:45:01.315518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 구현","metadata":{}},{"cell_type":"code","source":"#배운점\n    #3*3 kernel 을 사용하면 왜 7*7 보다 파라미터가 줄어드는지\n    # adam 최적화 기법 : 관성과 변수별 학습률을 고려한 최적의 최적화기법\n    # relu singmoid -> 이진분류 identity -> 회귀\n    # batch normal -> \n    # 기울기 소실문제 합성 함수의 미분을 구하는것은 계속해서 곱해나간단 소린데 1보다작은수를 계속 곱해나가면 기울기가 계속 줄어듬\n    # ? 왜 모델이 깊어질수록 비선형성이 증가하는가\n    # ? 왜 channel을 점점 키우는 걸까 키우면 왜 보통 2배씩 커지지\nfrom keras.layers import BatchNormalization\ndef build_model():\n    input_img = Input(shape=(224,224,3), name='ImageInput')\n    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n    x = MaxPooling2D((2,2), name='pool1')(x)\n    \n    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n    x = MaxPooling2D((2,2), name='pool2')(x)\n    \n    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n    x = BatchNormalization(name='bn1')(x)\n    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n    x = BatchNormalization(name='bn2')(x)\n    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n    x = MaxPooling2D((2,2), name='pool3')(x)\n    \n    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n    x = BatchNormalization(name='bn3')(x)\n    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n    x = BatchNormalization(name='bn4')(x)\n    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n    x = MaxPooling2D((2,2), name='pool4')(x)\n    \n    x = Flatten(name='flatten')(x)\n    x = Dense(1024, activation='relu', name='fc1')(x)\n    x = Dropout(0.7, name='dropout1')(x)\n    x = Dense(512, activation='relu', name='fc2')(x)\n    x = Dropout(0.5, name='dropout2')(x)\n    x = Dense(2, activation='softmax', name='fc3')(x)\n    \n    model = Model(inputs=input_img, outputs=x)\n    return model\n\nmodel = build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:45:05.484853Z","iopub.execute_input":"2021-11-14T11:45:05.485602Z","iopub.status.idle":"2021-11-14T11:45:07.538196Z","shell.execute_reply.started":"2021-11-14T11:45:05.485547Z","shell.execute_reply":"2021-11-14T11:45:07.537309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 학습","metadata":{}},{"cell_type":"code","source":"#배우점 \n    # keras 함수가 다함\n    # model (compile, fit_generator) , earlystopping, modelcheckpoint\n    #fit fit_generator 차이 \nfrom tensorflow.keras.optimizers import Adam\nopt = Adam(lr=0.0001, decay=1e-5)\nes = EarlyStopping(patience=5)\nchkpt = ModelCheckpoint(filepath='best_model_todate', monitor = 'loss', mode = 'min' , save_best_only=True, save_weights_only=True)\nmodel.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer=opt)\nbatch_size = 16\nnb_epochs = 20\n\n# Get a train data generator\ntrain_data_gen = data_gen(data=train_data, batch_size=batch_size)\n\n# Define the number of training steps\nnb_train_steps = train_data.shape[0]//batch_size\n\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps, len(valid_data)))\nhistory = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n                               validation_data=(valid_data, valid_labels),callbacks=[es, chkpt],\n                               class_weight={0:1.0, 1:0.4})","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:45:10.538315Z","iopub.execute_input":"2021-11-14T11:45:10.538592Z","iopub.status.idle":"2021-11-14T11:55:30.352561Z","shell.execute_reply.started":"2021-11-14T11:45:10.538564Z","shell.execute_reply":"2021-11-14T11:55:30.35047Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model test","metadata":{}},{"cell_type":"code","source":"model.load_weights(\"../input/xray-best-model/best_model/best_model_todate.hdf5\")\n\nnormal_cases_dir = test_dir / 'NORMAL'\npneumonia_cases_dir = test_dir / 'PNEUMONIA'\nnormal_cases = normal_cases_dir.glob('*.jpeg')\npneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\ntest_data = []\ntest_labels = []\n\nfor img in normal_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    else:\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.\n    label = to_categorical(0, num_classes=2)\n    test_data.append(img)\n    test_labels.append(label)\n    \n    for img in pneumonia_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    else:\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.\n    label = to_categorical(1, num_classes=2)\n    test_data.append(img)\n    test_labels.append(label)\n    \n\ntest_data = np.array(test_data)\ntest_labels = np.array(test_labels)\n\nprint(\"Total number of test examples: \", test_data.shape)\nprint(\"Total number of labels:\", test_labels.shape)\n\ntest_loss, test_score = model.evaluate(test_data, test_labels, batch_size=16)\nprint(\"Loss on test set: \", test_loss)\nprint(\"Accuracy on test set: \", test_score)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-12T08:05:04.422369Z","iopub.execute_input":"2021-11-12T08:05:04.422755Z","iopub.status.idle":"2021-11-12T08:05:04.455795Z","shell.execute_reply.started":"2021-11-12T08:05:04.422663Z","shell.execute_reply":"2021-11-12T08:05:04.454654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 정확도 정밀도 확인","metadata":{}},{"cell_type":"code","source":"# 배운점 \n    # 이진분류에서 편차가 큰경우 정확도(accuracy는 중요치 않음 정밀도(precision)와 재현율(recall)이 중요)\n\npreds = model.predict(test_data, batch_size=16)\npreds = np.argmax(preds, axis=-1)\n\n# Original labels\norig_test_labels = np.argmax(test_labels, axis=-1)\n\nprint(orig_test_labels.shape)\nprint(preds.shape)\n\ncm  = confusion_matrix(orig_test_labels, preds)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True, alpha=0.7,cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.show()\n\ntn, fp, fn, tp = cm.ravel()\n\nprecision = tp/(tp+fp)\nrecall = tp/(tp+fn)\n\nprint(\"Recall of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}