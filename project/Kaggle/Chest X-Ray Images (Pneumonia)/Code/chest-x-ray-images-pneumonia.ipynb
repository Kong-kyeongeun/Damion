{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-08T16:08:53.251744Z","iopub.execute_input":"2021-11-08T16:08:53.252129Z","iopub.status.idle":"2021-11-08T16:08:53.280726Z","shell.execute_reply.started":"2021-11-08T16:08:53.252007Z","shell.execute_reply":"2021-11-08T16:08:53.280110Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# **import**","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\n","metadata":{"execution":{"iopub.status.busy":"2021-11-08T16:08:53.282199Z","iopub.execute_input":"2021-11-08T16:08:53.282634Z","iopub.status.idle":"2021-11-08T16:08:53.285869Z","shell.execute_reply.started":"2021-11-08T16:08:53.282602Z","shell.execute_reply":"2021-11-08T16:08:53.285227Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob # 데이터 전처리 할때, 파일 불러올 때 사용\nimport h5py # 대용량의 데이터 빠르게 읽고 쓰기\nimport shutil\nimport imgaug as aug\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mimg\nimport imgaug.augmenters as iaa\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom PIL import Image\nfrom pathlib import Path\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import layer_normalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom tensorflow.keras.optimizers import SGD\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nfrom keras import backend as K\ncolor = sns.color_palette()\n%matplotlib inline\n\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-11-08T16:08:53.286909Z","iopub.execute_input":"2021-11-08T16:08:53.287421Z","iopub.status.idle":"2021-11-08T16:09:02.138677Z","shell.execute_reply.started":"2021-11-08T16:08:53.287386Z","shell.execute_reply":"2021-11-08T16:09:02.137937Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 데이터 불러오기","metadata":{}},{"cell_type":"code","source":"# 데이터 경로 지정\ndata_dir = Path('../input/chest-xray-pneumonia/chest_xray/chest_xray')\ntrain_dir = data_dir/'train'\nval_dir = data_dir/ 'val'\ntest_dir = data_dir/ 'test'\n\nnormal_cases_dir = train_dir / 'NORMAL'\npneumonia_cases_dir = train_dir / 'PNEUMONIA'\n\nnormal_cases = normal_cases_dir.glob('*.jpeg')\npneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n\n# train set 만들기\ntrain_data = []\nfor img in normal_cases:\n    train_data.append((img, 0))\n    \nfor img in pneumonia_cases:\n    train_data.append((img, 1))\n\ntrain_data = pd.DataFrame(train_data, columns=['image', 'label'], index = None)\n\n# data shuffle ? 왜하는 거임\ntrain_data = train_data.sample(frac=1.).reset_index(drop=True)\n\n#데이터 확인\ntrain_data[train_data['label']==1]\n\ncases_count = train_data['label'].value_counts()\nprint(cases_count)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T16:14:39.875402Z","iopub.execute_input":"2021-11-08T16:14:39.876024Z","iopub.status.idle":"2021-11-08T16:14:39.919696Z","shell.execute_reply.started":"2021-11-08T16:14:39.875979Z","shell.execute_reply":"2021-11-08T16:14:39.918308Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# 데이터 예시 보기","metadata":{}},{"cell_type":"code","source":"# 데이터 몇개 추출 \n# 배운점 \n    #to_list 역할 : dataframe 을 list로 변경해주어 for문 돌수있게 함\n    #loc iloc 차이 : loc은 값으로 원소에 접근하는거 iloc 은 index로 접근하는거\npneumonia_samples = (train_data[train_data['label']==1]['image'].iloc[:5]).tolist()\nnormal_samples = (train_data[train_data['label']==0]['image'].iloc[:5]).tolist()\n\nsamples = pneumonia_samples + normal_samples\ndel pneumonia_samples, normal_samples\n\nf, ax = plt.subplots(2,5, figsize=(30,10))\nfor i in range(10):\n    img = imread(samples[i])\n    ax[i//5, i%5].imshow(img, cmap='gray')\n    if i<5:\n        ax[i//5, i%5].set_title(\"Pneumonia\")\n    else:\n        ax[i//5, i%5].set_title(\"Normal\")\n    ax[i//5, i%5].axis('off')\n    ax[i//5, i%5].set_aspect('auto')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-08T16:16:03.442017Z","iopub.execute_input":"2021-11-08T16:16:03.442848Z","iopub.status.idle":"2021-11-08T16:16:06.534866Z","shell.execute_reply.started":"2021-11-08T16:16:03.442783Z","shell.execute_reply":"2021-11-08T16:16:06.534137Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# 배운점 \n    #os.listdir = 해당 디렉토리 파일명만 가져옴\n    #glob = 해당 디렉토리의 경로명까지 가져옴 ->내생각엔 사진을 불러오는 느낌이라기 보단 경로를 불러오는 느낌\n    #glob 은 generator를 반환함 \n    #dstack, stack, concatenate 차이 \nnormal_cases_dir = val_dir / 'NORMAL'\npneumonia_cases_dir = val_dir / 'PNEUMONIA'\n\nnormal_cases = normal_cases_dir.glob('*.jpeg')\npneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n\nvalid_data = []\nvalid_labels = []\n\nfor img in normal_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224)) ## 데이터 사이즈를 224로 줄여서 얻는 점 -> 크기 통일, 메모리 사용량 줄임 ?보통 몇으로 줄일까\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img]) # black 을 rgb로 즉 채널 1에서 3으로 확장\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255. #정규화 \n    label = to_categorical(0, num_classes=2)\n    valid_data.append(img)\n    valid_labels.append(label)\n\nfor img in pneumonia_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.\n    label = to_categorical(1, num_classes=2)\n    valid_data.append(img)\n    valid_labels.append(label)\n    \n# Convert the list into numpy arrays\nvalid_data = np.array(valid_data)\nvalid_labels = np.array(valid_labels)\n\nprint(\"Total number of validation examples: \", valid_data.shape)\nprint(\"Total number of labels:\", valid_labels.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-08T14:31:18.694371Z","iopub.execute_input":"2021-11-08T14:31:18.695449Z","iopub.status.idle":"2021-11-08T14:31:18.93892Z","shell.execute_reply.started":"2021-11-08T14:31:18.6954Z","shell.execute_reply":"2021-11-08T14:31:18.93817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq = iaa.OneOf([\n    iaa.Fliplr(), # horizontal flips\n    iaa.Affine(rotate=20), # roatation\n    iaa.Multiply((1.2, 1.5))]) #random brightness","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#배운점\n    # enumerate j, idx 로 for문 돌아야함 j = index idx = 값\n    #float32 타입으로 바꾼후 하는 거였음 255.도 주의\n    #data_generator 함 수 만드는게 전부네\ndef data_gen(data, batch_size):\n\n    n = len(data)\n    steps = n//batch_size\n    \n    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n    batch_labels = np.zeros((batch_size,2), dtype=np.float32)\n\n    indices = np.arange(n)\n    \n    i =0\n    while True:\n        np.random.shuffle(indices)\n        count = 0\n        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n        for j, idx in enumerate(next_batch): \n            img_name = data.iloc[idx]['image']\n            label = data.iloc[idx]['label']\n            \n            encoded_label = to_categorical(label, num_classes=2)\n            img = cv2.imread(str(img_name))\n            img = cv2.resize(img, (224,224))\n            \n            if img.shape[2]==1:\n                img = np.dstack([img, img, img])\n            \n            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            orig_img = img.astype(np.float32)/255. \n            \n            batch_data[count] = orig_img\n            batch_labels[count] = encoded_label\n            \n            #undersample 즉 sample 개수가 차이나니까 적은거 augment 해서 늘리는 거 같음\n            if label==0 and count < batch_size-2:\n                aug_img1 = seq.augment_image(img)\n                aug_img2 = seq.augment_image(img)\n                aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n                aug_img2 = cv2.cvtColor(aug_img2, cv2.COLOR_BGR2RGB)\n                aug_img1 = aug_img1.astype(np.float32)/255.\n                aug_img2 = aug_img2.astype(np.float32)/255.\n\n                batch_data[count+1] = aug_img1\n                batch_labels[count+1] = encoded_label\n                batch_data[count+2] = aug_img2\n                batch_labels[count+2] = encoded_label\n                count +=2 # 왜 3이 아니지?\n            \n            else:\n                count+=1\n            \n            if count==batch_size-1:\n                break\n            \n        i+=1\n        yield batch_data, batch_labels\n            \n        if i>=steps: #반복문은 언제 탈출?\n            i=0","metadata":{"execution":{"iopub.status.busy":"2021-11-08T14:48:53.078807Z","iopub.execute_input":"2021-11-08T14:48:53.079368Z","iopub.status.idle":"2021-11-08T14:48:53.099296Z","shell.execute_reply.started":"2021-11-08T14:48:53.079324Z","shell.execute_reply":"2021-11-08T14:48:53.098381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}